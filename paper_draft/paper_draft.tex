\documentclass[amsmath, prl, reprint, aps]{revtex4-1}
\usepackage{ulem}
\usepackage{bm}
\usepackage{makecell}
\usepackage{graphicx}
\usepackage{hyperref}
\hypersetup{
    colorlinks   = true, %Colours links instead of ugly boxes
    urlcolor     = blue, %Colour for external hyperlinks
    linkcolor    = black, %Colour of internal links
    citecolor   = red %Colour of citations
}

\renewcommand{\arraystretch}{1.25}
\newcommand{\yv}{\textbf{y}}
\newcommand{\sv}{\textbf{s}}
\newcommand{\Lv}{\textbf{L}}
\newcommand{\nv}{\textbf{n}}
\newcommand{\qv}{\textbf{q}}
\newcommand{\Cv}{\textbf{C}}
\newcommand{\Sv}{\textbf{S}}
\newcommand{\Nv}{\textbf{N}}

\newcommand{\cov}{\textbf{C}}

\newcommand{\xv}{\textbf{x}}
\newcommand{\kv}{\textbf{k}}
\newcommand{\Kv}{\textbf{\textit{K}}}
\newcommand{\tpc}{(2 \pi)^3}
\newcommand{\DTT}{\frac{\Delta T}{T}}

\newcommand{\dv}{\textbf{d}}
\newcommand{\donev}{\textbf{d}_1}
\newcommand{\dtwov}{\textbf{d}_2}
\newcommand{\tv}{\bm{\theta}}
\newcommand{\tML}{\tv^{\rm ML}}


% define symbols
\newcommand{\rv}{\textbf{r}}
\newcommand{\Bl}{\Big \langle}
\newcommand{\Br}{\Big \rangle}

\newcommand{\lnR}{\ln R_{12}}

\newcommand{\saroj}[1]{\textcolor{blue}{(Saroj: #1)}}
\newcommand{\dragan}[1]{\textcolor{red}{(DH: #1)}}

\begin{document}
    \title{A new {Bayesian evidence-based} measure of tension between experiments} %{A new statistic to measure tension between experiments}    
    \author{Saroj Adhikari} \email{saroj@umich.edu}
    \author{Dragan Huterer} \email{huterer@umich.edu}    
    \affiliation{Department of Physics, University of Michigan, 450 Church St, Ann Arbor, MI 48109-1040;\\ 
        Leinweber Center for Theoretical Physics, University of Michigan, 
        450 Church St, Ann Arbor, MI 48109-1040}
    \date{\today}
    
    \begin{abstract}
        %\dragan{\sout{With many cosmological surveys, we now have data from multiple observables that probe the same underlying cosmological model. As the surveys get better, the statistical errors on the parameters of the cosmological models are getting smaller. As a result, a number of interesting but mild level of tension between parameter values obtained from different surveys exist. Several tests have been devised to probe the {consistency} of two datasets given a cosmological model. Some of the widely used statistical tests have undesired properties or additional requirements such as dependence on the prior volume or requiring near-Gaussian posterior distributions. We propose a quantity defined as an evidence ratio in which these undesired properties are absent. We devise and test the quantity on simple one-parameter and two-parameter models with Gaussian and non-Gaussian likelihoods. Similar to a likelihood ratio or a Bayes factor, the dataset evidence ratio can be evaluated on the empirically calibrated Jeffreys scale. Applying the statistic to the Planck data, we find moderate discrepancy $\sim (2-3)\sigma$ when comparing TT and EE power spectra and when splitting the TT spectrum into small and large scales.}}\\
        Tensions between cosmological measurements by different surveys or probes have always been important --- and are presently much discussed --- as they may lead to evidence of new physics.  Several tests have been devised to probe the consistency datasets given a cosmological model, but they often have undesired features such as dependence on the Bayesian priors given to parameters, or burdensome requirements such as that of near-Gaussian posterior distributions. We propose a new quantity, defined in a similar way as the Bayesian evidence ratio and calibrated using the familiar Jeffreys scale, in which these undesired properties are absent. We test the quantity on simple models with Gaussian and non-Gaussian likelihoods. We then apply it to data from the {\it Planck} satellite: we investigate the consistency of the TT and EE angular power spectrum measurements, as well as the mutual consistency of small- and large-angle portion of each measurement, finding mild ($\sim$2-$3\,\sigma$) discrepancies in agreement with previous work. 
    \end{abstract}
    
    \maketitle
    %\saroj{putting the alternative one only here to avoid confusion; the old text is still in main.tex}
    \medskip
    \textit{Introduction.}
    The use of Bayesian statistics in cosmology is now commonplace: most of the results on cosmological parameters from cosmic microwave background (CMB) experiments \cite{Ade:2015xua} and large-scale structure (LSS) surveys \cite{Abbott:2017wau} are reported as posterior distributions. In addition, various Bayesian methods are used for model comparison \cite{Trotta:2008qt}.
    
    Along with the increase in the number of cosmological surveys and the improvement in their precision, a number of tensions between  parameters derived from different experiments have been observed. For example, the Hubble constant measured using the distance ladder in the local universe disagrees with that derived from Planck CMB observations; in the standard six parameter $\Lambda$CDM model, the disagreement is about $3.4\sigma$ \cite{Riess:2016jrr, Bernal:2016gxb}. There is also some tension between the measurements of the amplitude of fluctuations $\sigma_8$ and the matter density $\Omega_m$ from weak lensing to that of the measurement from {\it Planck} CMB data \citep{Hildebrandt:2016iqg,Troxel:2017xyo,Troxel:2018qll}. As a result, a number of statistics have been developed to compare datasets in cosmology. The primary goal of these statistics is to determine if two datasets are consistent realizations of the same model, that is, with a single set of cosmological parameters (see \cite{Seehars:2015qza, Charnock:2017vcd, Lin:2017ikq} for discussions and comparisons of some of the popular methods). 
    
    The Bayesian evidence-based metric of \cite{Marshall:2004zd} has been widely used in cosmology \cite{March:2011rv, Amendola:2012wc, Joudaki:2016mvz, Raveri:2015maa} but is known to strongly depend on the priors given to parameters. This has led to the use of other measures \cite{Seehars:2014ora,Grandis:2016fwl, Feeney:2018mkj} that do not have the prior-volume dependence, but at the expense of losing the simplicity of an evidence ratio. 
    In this work, we define an evidence-based quantity which fixes the problem of prior volume dependence and which can be evaluated on a easy-to-interpret scale.
    
    Consider two datasets $\dv_1$ and $\dv_2$, and let $\tv$ be the  parameters of a model. Let us assume that both the datasets and the combination of them can be modeled by a particular $\Lambda$CDM realization, and the priors are wide enough to include the parameter posteriors preferred by both the datasets individually. Most commonly, a Bayesian analysis is used to determine posterior probability distributions for the model parameters $\tv$. Suppose the two datasets separately give two (normalized) posterior distributions:
    \begin{equation}
    \begin{aligned}
    p_1(\tv | \dv_1) &= \frac{ \mathcal{L}(\dv_1|\tv) \pi(\tv)}{E(\dv_1)} \\
    p_2(\tv | \dv_2) &= \frac{\mathcal{L}(\dv_2|\tv) \pi(\tv)}{E(\dv_2)},
    \label{eq:p1p2}
    \end{aligned}
    \end{equation}
    where $\mathcal{L}(\dv|\tv)$ denotes the likelihood of the data $\dv$ given the model defined by a set of parameters $\tv$, $\pi(\tv)$ is the prior probability of the model parameters, and $E$ is called the marginal likelihood or the evidence,
    \begin{align}
        E(\dv) &= \int d\tv \mathcal{L}(\dv|\tv) \pi(\tv).
        \label{eq:evidence}
    \end{align}
    
    We will always use normalized probability density functions for the likelihood ($\int \mathcal{L}(\dv|\theta) d\dv = 1$) and the prior  ($\int \pi(\tv) d \tv =1$). The posterior for the combination of datasets $\dv_1, \dv_2$ is:
    \begin{equation}
    \begin{aligned}
    \!\!\!
    p_{12}(\theta|\dv_1,\dv_2) = \frac{\mathcal{L}(\dv_1, \dv_2, \tv) \pi(\tv)}{E(\dv_1, \dv_2)}   = \frac{\mathcal{L}(\dv_1, \tv) \mathcal{L}(\dv_2, \tv) \pi(\tv)}{E(\dv_1, \dv_2)},
    \end{aligned}
    \end{equation}
    where the second equality assumes that the combined likelihood is approximated well by the product of the likelihoods, which holds if the datasets are independent.
    
    The ratio of the evidences Eq.(\ref{eq:evidence}) obtained using two different models, called the Bayes Factor, is a widely used measure for model comparison. In this work, we will define a similar ratio to compare two sets of parameter constraints of a model obtained using different datasets or experiments. 
    % \sout{Some attempts has been made to use ratio of evidences for %comparing model parameters (for the same underlying model) %obtained using different datasets, however not without problems} %\dragan{(what problems?)} \cite{Marshall:2004zd, Grandis:2016fwl} 
    %\saroj{we have discussed this in the introduction too; let me try to rephrase this without referring to other works}. 
    %\sout{We attempt to remedy the situation.}
    % We first introduce a definition of Bayesian evidence for the maximum likelihood parameters (rather than the observed data realization), and then motivate and define the dataset-evidence ratio. We finally apply this ratio to test the consistency between Planck TT and EE spectra, and large and small scale Planck TT multipole. 
    
    \medskip
    \textit{Evidence for model parameters.}
    We first define the marginal likelihood (or the evidence) for the maximum likelihood model parameters, $\tML$, instead of the usual definition of the evidence for the data, $\dv$. We do so as our primary goal is to quantify the level of consistency between model parameters obtained from different datasets or experiments. Analogous to Eq.~(\ref{eq:evidence}), we define the evidence for the maximum likelihood model parameters
    \begin{align}
        E(g(\tML)) &= \int d\tv \mathcal{L}(g(\tML)|\tv) \pi(\tv),
    \end{align}
    where instead of the measured data, we have used the maximum likelihood value of the data realization given the model, $g(\tML)$; see Figure \ref{fig:gtheta} for an illustration. Here we have denoted $g(\tv)$ as the function that computes the model prediction for the data given the parameters $\tv$; for example, in the case of the CMB temperature fluctuation data, the model prediction is represented by the theory angular power spectra $g_{\rm cmb}^{TT} = \{C_\ell^{TT}\}$ which can be obtained using standard Boltzmann codes like \texttt{camb}. If the likelihood in the above equation is a combination of two experiments, then we can define evidences for the maximum likelihood parameters obtained through the combination of the two datasets (denoted by $i,j$), $E(g(\tML_{ij}))$, or we can also define an evidence so that each part of the data vector in the evidence integral uses its own maximum likelihood parameter values, obtained by analyzing each experiment separately, $E(\{g_i(\tML_i), g_j(\tML_j)\})$. As we will show next, we can then use the ratio of the two evidences to quantify the tension between the parameter constraints obtained from two different datasets.
    
    \begin{figure}
        \includegraphics[width=0.5\textwidth]{../code/gtheta_new2.pdf}
        \caption{Illustration of how we make use of the maximum-likelihood data-realizations (crosses) as opposed to the actual measurements (dots) in our evidence integrals. Doing this gets rid of the data scatter and therefore makes our statistic only sensitive to the model parameters and not the spread in the data realizations.}
        \label{fig:gtheta}
    \end{figure}
    
    \medskip
    \textit{Evidence-based dataset comparison.}
    For simplicity, consider two datasets that have independent likelihoods, $\mathcal{L}_i(\dv|\tv), \mathcal{L}_j(\dv|\tv)$, and let the measured data vector for each experiment be denoted by $\dv_i, \dv_j$. Let us further assume that the maximum likelihood parameters of the model, say $\Lambda$CDM for example, are known for three different cases: two datasets analyzed separately, $\tML_i, \tML_j$, and their combined analysis, $\tML_{ij}$.
    
    Our null hypothesis, $\mathcal{H}_0$ is that both the datasets are realizations of a single set of parameters, $\tML_{ij}$, from the combined fit. The alternative, more complicated, hypothesis, $\mathcal{H}_1$ is that each of the datasets are realizations of their own set of parameters, $\tML_i, \tML_j$. Then, using the Bayes theorem similar to the derivation of the Bayes factor, we get
    \begin{equation}
    \begin{aligned}
    \frac{p(\mathcal{H}_1)}{p(\mathcal{H}_0)} &= \frac{\int d\tv \pi(\tv) \mathcal{L}_i(g_i(\tML_i)|\tv) \mathcal{L}_j(g_j(\tML_j)|\tv)}{\int d\tv \pi(\tv) \mathcal{L}_i(g_i(\tML_{ij})|\tv) \mathcal{L}_j(g_j(\tML_{ij})|\tv)} \label{eq:DER} \\
    &= \frac{E_{ij}^{\rm sep}}{{E_{ij}^{\rm com}}} \equiv R_{ij},
    \end{aligned}
    \end{equation}
    where the superscripts \texttt{sep} and \texttt{com} in the formula above stand for separate and combined maximum likelihood parameters, respectively. The logarithm of $R_{ij}$ can be evaluated on the empirically calibrated Jeffreys scale presented in \cite{Trotta:2008qt}. Alternatively, we can consider $(-2\ln R_{ij})$ which is on the same scale as a likelihood-ratio test \cite{kassr95}, and assuming that Wilks theorem \cite{Wilks} holds in the cases considered, we can compute a probability-to-exceed value for a measured dataset-evidence ratio by assuming that $(-2\ln R_{ij})$ is $\chi^2$ distributed. We demonstrate analytically in the next section that $-2\ln R_{ij}$ is $\chi^2$-distributed for the case of two datasets and Gaussian posteriors. This also means that we may be able to extend the formula in Eq.~(\ref{eq:DER}) to more than two datasets, by evaluating the probability-to-exceed of $(-2\ln R_{123...N})$ assuming that it is $\chi^2_{N-1}$ distributed. We will, however, only consider $N=2$ in this work.
    
    As we will show next, the logarithm of the {dataset-evidence ratio} defined above reduces to the intuitive $\chi^2$ notion of discrepancy between parameters, which is named the Index of Inconsistency (IOI) by \cite{Lin:2017ikq} when the posteriors are multivariate Gaussian distributed. Also, we should note that the ratio is somewhat related to the \textit{tension} measure defined in \cite{Verde:2013wza}, because in some situations $E_{ij}^{\rm com}$ can be approximated by shifting one of the posterior probability density functions while preserving its shape. However, there can be ambiguity in the process of shifting one or both of the posterior distributions (for non-Gaussian and multimodal distributions), as discussed in Section X.B. of \cite{Lin:2017ikq}. That ambiguity is removed in our definition, as we reference the likelihood functions directly. 
    
    We provide an example in Figure \ref{fig:example1}, in which the Gaussian likelihood is simply, $\mathcal{L}_1(d|\theta) = \mathcal{N}(d, 1)$, where $\mathcal{N}(\mu, \sigma)$ denotes a normal probability distribution. The non-Gaussian likelihood is a (normalized) sum of two Gaussians defined as: $\mathcal{L}_2(d|\theta) = 0.9 \mathcal{N}(d, 1) + 0.1 \mathcal{N}(d+3, 0.1)$. The distributions plotted in Figure \ref{fig:example1} are $\mathcal{L}_1(d=-0.5|\theta)$ (dashed) and $\mathcal{L}_2(d=0|\theta)$ (solid). Because the combined fit is insensitive to the narrow peak near $\theta=3$, we get $\ln R_{12}=-0.064$ without any ambiguity in how to shift the distributions, which shows that the two sets of parameters $\theta_1=-0.5$ and $\theta_2=0$ from the two likelihoods are very consistent, as expected. Without the additional peak at $\theta=3$, the level of consistency is slightly better: $\ln R_{12} = -0.5\times(0.5^2)/2 = -0.0625$.
    
    \begin{figure}
        \centering
        \includegraphics[width=0.48\textwidth]{../code/nongaus2.pdf}
        \caption{In this example, we verify that the two distributions shown in the figure: (i) Gaussian (dashed), and (ii) non-Gaussian (solid), are consistent with each other; the effect of the peak around $\theta=3$ in the non-Gaussian distribution is small and the dataset-evidence ratio $\ln R_{12}=-0.064$ shows that the two distributions are consistent, as expected.}
        \label{fig:example1}
    \end{figure}
    
    The previous example was for the case of a single parameter. Now, we consider $N>1$ parameters. Suppose that the two likelihood functions are given by two $N$ dimensional multivariate Gaussian distributions with arbitrary covariance matrices $\Sigma_1$ and $\Sigma_2$, such that the two likelihoods are,
    \begin{align}
        \mathcal{L}_1(\tv) =& \frac{1}{\sqrt{\det(2\pi \Sigma_1)}} \exp\left[{-\frac{1}{2}}(\donev-\tv)^T \Sigma_1^{-1} (\donev-\tv)\right] \nonumber \\
        \mathcal{L}_2(\tv) =& \frac{1}{\sqrt{\det(2\pi \Sigma_2)}} \exp\left[{-\frac{1}{2}}(\dtwov-\tv)^T \Sigma_2^{-1} (\dtwov-\tv)\right]\nonumber
    \end{align}
    
    In this simple example, we have taken $g_{i,j}(\tv) = \tv$ so that the expressions can be evaluated analytically. If we further assume that the prior on each of the parameters is uniform and wide (compared to the constraint on the parameter), we get \cite{IMM2012-03274},
    %\begin{equation}
    \begin{align}
        \nonumber
        E_{12}^{\rm sep} &\propto \int d\tv \mathcal{L}_1(\dv_1|\tv) \mathcal{L}_2(\dv_2|\tv) 
        = \frac{1}{\sqrt{\det\left[2\pi(\Sigma_1+\Sigma_2)\right]}} \\ & \times\exp \left[-\frac{1}{2}(\donev-\dtwov)^T(\Sigma_1+\Sigma_2)^{-1}(\donev-\dtwov)\right] 
        \\[0.1cm]
        E_{12}^{\rm com} &\propto \int d\tv \mathcal{L}_1(\dv_{12}|\tv) \mathcal{L}_2(\dv_{12}|\tv)  
        = \frac{1}{\sqrt{\det\left[2\pi(\Sigma_1 + \Sigma_2)\right]}}
        \nonumber
    \end{align}
    % \end{equation}
    so that
    \begin{align}
        \!\!\!
        R_{12} =& \exp \left[-\frac{1}{2}(\donev-\dtwov)^T(\Sigma_1+\Sigma_2)^{-1}(\donev-\dtwov)\right], \label{eq:R12NGaus}
    \end{align}
    the logarithm of which ($-\ln R_{12}$) is the index of inconsistency (IOI) defined in \cite{Lin:2017ikq}. That is, our more general definition of the dataset evidence ratio given in Eq.~(\ref{eq:DER}) reduces to the intuitive notion of inconsistency for Gaussian posteriors from two experiments and uniform wide priors. We expect the more general definition to work well when the posteriors are non-Gaussian.
    In the next section, we provide example calculations of $\ln R_{12}$ using different pairs of datasets (e.g. TT vs EE) from the {\it Planck} satellite, in which case $g_i(\tv)$ is no more a simple linear function but has to evaluated numerically.
    
    %\saroj{perhaps mention the $n-\sigma \sim \sqrt{-2\ln R_{12}}$ connection as done by \cite{Lin:2017bhs} also:} 
    Calibrating the level of discrepancy between two datasets on Eq.~(\ref{eq:R12NGaus}), we can define the effective n-$\sigma$ discrepancy as $\sqrt{-2 \ln R_{12}}$ \cite{Lin:2017bhs}. This is the value we use whenever we quote a n-$\sigma$ discrepancy rather than $\ln R_{12}$ in the rest of the paper. Next, we apply the dataset-evidence ratio to {\it Planck} angular power spectrum data and compare our conclusions to previous works that studied discrepancies in the {\it Planck} parameter constraints using other methods.
    
    \medskip
    \textit{Application to Planck data.} 
    We use the binned and foreground marginalized \texttt{plik\_lite} likelihood from the Planck collaboration \cite{Aghanim:2015xee} which includes multipoles $30-2508$ for TT power spectrum, and multipoles $30-1996$ for EE power spectrum. We fix the {\it Planck} calibration factor $y_p$ to 1; see Sec. C.6.2 of \cite{Aghanim:2015xee}, from which the CMB-only Gaussian \texttt{plik\_lite} likelihood is:
    \begin{align}
        \ln \mathcal{L}(\tilde{C}_b^{\rm CMB}|C_b^{\rm th}) = -\frac{1}{2}\xv^T \tilde{\Sigma}^{-1} \xv, \label{eq:PlancklnL}
    \end{align}
    where $\xv = \tilde{C}_b^{\rm CMB}/y_p^2 - C_b^{\rm th}$. The binned and marginalized mean $\tilde{C}_b^{\rm CMB}$ and covariance matrix $\tilde{\Sigma}$ are provided by the {\it Planck} team. To evaluate the likelihood in Eq.~(\ref{eq:PlancklnL}), we compute lensed $C_\ell^{\rm th}$ for a given set of parameters $\tv$ using \texttt{camb} \cite{Lewis:1999bs,Howlett:2012mh} and bin the $C_\ell^{\rm th}$ using the appropriate weights to get $C_b^{\rm th}$.
    
    %\dragan{(rearranging:)}
    Without low-multipole polarization data, the optical depth to reionization $\tau$ is only weakly constrained and is strongly degenerate with the amplitude of scalar fluctuations $A_s$. To break this degeneracy, we use a low-$\ell$ polarization prior $\tau = 0.07\pm0.02$. The evidences we compute are:
    \begin{equation}
    \begin{aligned}
    \!\!\!
    E^{\rm sep}_{\rm TT, EE} =& \int d\tv\, \pi(\tv)  
    \mathcal{L}(\{C_\ell^{\rm TT}(\tML_T), C_\ell^{\rm EE}(\tML_E)\}|\tv)  \\
    \!\!\!
    {E}^{\rm com}_{\rm TT, EE} =& \int d\tv\, \pi(\tv)  
    \mathcal{L}(\{C_\ell^{\rm TT}(\tML_C), C_\ell^{\rm EE}(\tML_C)\}|\tv)
    \end{aligned}
    \end{equation}
    where $\tML_T$ and $\tML_E$ are obtained individually by using the respective TT and EE data, while $\tML_C$ is the maximum likelihood model parameters from the combined fit. We obtain the maximum likelihood values $\tML$ by using a global optimization algorithm {\tt differential\_evolution} \cite{Storn1997} implemented in {\tt scipy} \cite{scipy}. We calculate the evidences using the \texttt{MultiNest} package \cite{Feroz:2007kg, Feroz:2008xx}, and quote results and statistical errorbars produced by the importance nested sampling method \cite{Feroz:2013hea}. We take uniform priors on six cosmological parameters with the following limits for evidence calculations and when searching for maximum-likelihood parameters: \begin{align}\ln (10^{10} A_s) &= \{2.7, 3.4\}, \nonumber \\ n_s &= \{0.8, 1.2\}, \nonumber \\ H_0 &=\{50, 95\}, \nonumber \\ \Omega_c &=\{0.1, 0.45\}, \nonumber \\ \Omega_b &= \{0.044, 0.056\}, \nonumber \\ \tau &=\{0.005, 0.2\}. \nonumber \end{align} 
    {$A_s$ and $n_s$ are the amplitude and spectral index of the primordial scalar fluctuations, $H_0$ is the Hubble constant, $\Omega_c$ and $\Omega_b$ are the cold dark matter and baryonic matter densities, and $\tau$ is the optical depth to reionization.} The results are shown in Table \ref{table:lnRTEC}.  Our results are consistent with other studies that also find that there is no indication of strong discrepancy between these datasets \cite{Shafieloo:2016zga}, albeit by using more complicated methods, or by directly using the posteriors \cite{Lin:2017bhs}.
    
    \begin{table}[t]
        \centering
        \caption{Summary of applications of our new statistic to {\it Planck} data, discussed in the text. The left column shows the logarithm of the dataset-evidence ratio using {\it Planck} \texttt{plik\_lite} likelihood for TT and EE combined. The middle and right columns show the dataset-evidence ratio for splitting the data into two multipole ranges at $\ell_{\rm split}=1000$ using only TT (middle) or only EE (right) data.}
        \label{table:lnRTEC}
        \begin{tabular*}{0.48\textwidth}{c@{\extracolsep{\fill}} c  c}
            \hline
            $\ln R_{\rm TT,EE}$ & \thead{$\ln R_{\rm TT}$\\$(\ell_{\rm split}=1000)$} & \thead{$\ln R_{\rm EE}$\\$(\ell_{\rm split}=1000)$}\\
            \hline
            $-1.93 \pm 0.03$ & $-4.13 \pm 0.16 $ & $-0.83 \pm 0.16$ \\
            \hline\hline
        \end{tabular*}
    \end{table}
    
    We perform another test using the {\it Planck} data, by splitting the temperature data into $\ell<1000$ and $\ell \geq 1000$ samples and calculating the dataset-evidence ratio for these two datasets. We again find that the level of inconsistency is moderate with $\ln R_{\rm TTsplit} = -4.13 \pm 0.16$, which is consistent with previous studies using other statistics \cite{Addison:2015wyg} or simulations \cite{Aghanim:2016sns}, confirming that the {\it Planck} data in the context of $\Lambda$CDM in itself does not have strong inconsistency --- the parameter shifts become more interesting when we consider low-redshift probes that prefer different values of the Hubble constant $H_0$ \cite{Riess:2016jrr} and matter density $\Omega_m$ \cite{Abbott:2017wau}. Note that, for values in Table \ref{table:lnRTEC}, we are only using the \texttt{plik\_lite} likelihood and therefore low-$\ell$ ($\ell<30$) multipoles are not included; inclusion of these large-scale multipoles will likely increase the discrepancy as their amplitude is known to be anomalously low.
    
    To estimate the effect of low-$\ell$ part of the TT likelihood, we implement an approximation to the low-$\ell$ likelihood following \cite{Aghanim:2016sns} (see their Section 3.2 for details), which they have tested to find that the approximation gives similar cosmological parameters compared to the computationally more demanding pixel-space likelihood. To summarize: $f_\ell(2\ell+1) \hat{C}_\ell/C_\ell$ is drawn from a $\chi^2[f_\ell(2\ell+1)]$ probability distribution function, where $f_\ell$ are mask-dependent fitting factors determined for the {\tt commander} mask. Here $\hat{C}_\ell$ is the mask-deconvolved power spectrum, which we take to be the {\it Planck} {\tt commander} quadratic maximum likelihood (QML) $C_\ell$s. Any correlation between different multipoles for $\ell<30$ and with the {\tt plik\_lite} multipole bins is ignored. For $\ell_{\rm split}=1000$, including the approximate low-$\ell$ likelihood, we now get $\ln R_{\rm TTsplit}=-5.32 \pm 0.05$ or approximately $3.26\sigma$. 
    
    {We finally carry out a similar analysis with the polarization data: we split the {\it Planck} EE data in multipole, using the {\tt plik\_lite} likelihood for each multipole range}. The large and small scale multipole split for the EE spectrum results in consistent $\Lambda$CDM parameters: $\ln R_{\rm EEsplit}=-0.83\pm 0.16$, which is expected given the lesser constraining power of the EE spectrum for {\it Planck} noise levels. 
    
    \medskip
    \textit{Summary and Conclusion.} \label{sec:summary}
    We have introduced an evidence ratio, which can be used to quantify the level of discrepancy between model parameters from two datasets that are expected to be described by the same underlying model parameters. This is a common occurrence in cosmology where different observations are expected to be realizations of the same underlying cosmological model. While the notion of discrepancy is fairly straightforward to define for single parameter or multiparameter Gaussian distributions, the case of multidimensional non-Gaussian distributions is more complicated. 
    
    We have shown that our definition of the dataset-evidence ratio reduces to the expected discrepancy measure for Gaussian distributed posteriors, and gives sensible results in the non-Gaussian tests that we performed. Applying to the {\it Planck} power spectrum data, we could recover previously derived conclusions about the consistency between TT and EE measurements: that the level of inconsistency is moderate, at the level of $2 \sigma$. The level of discrepancy when splitting the TT spectrum into smaller and larger scales at $\ell_{\rm split}=1000$ is slightly larger at over $3\sigma$.
    
    We have limited our application to just the {\it Planck} data in this work. It is worthwhile to apply the dataset-evidence ratio to comparing the {\it Planck} constraints with weak-lensing constraints \cite{Abbott:2017wau} and smaller-scale CMB constraints \cite{Aylor:2017haa}. It will also be useful to consider using the statistic in the context of $\Lambda$CDM extensions. Further, we have only carefully investigated the ratio for comparing two datasets. We have conjectured that a straightforward application of the ratio for more than two datasets might be possible by evaluating $(-2\ln R)$ as $\chi^2$ distributed with $(N_{\rm datasets}-1)$ degrees of freedom, but detailed investigation of this possibility and application to other cosmological datasets is left for future study.
    
    \medskip
    \textit{Acknowledgments.}
    The authors are supported by NASA under contract 14-ATP14-0005. DH is also supported by DOE under
    Contract No. DE-FG02-95ER40899. This work used the Extreme Science and Engineering Discovery Environment (XSEDE), which is supported by National Science Foundation grant number ACI-1548562. We thank Marius Millea for providing the necessary $f_\ell$ coefficients and example code to implement the low-$\ell$ approximated likelihood.
    
    \bibliography{dataset_evidence_ratio.bib}
    
    
\end{document}


